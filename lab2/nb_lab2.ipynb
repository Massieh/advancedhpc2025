{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJGofTYFElJV"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B76-4WgIETBq",
        "outputId": "acf16288-3a8d-4ece-f166-ff9e7809e2cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.12/dist-packages (from numba) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numba\n",
        "import numba\n",
        "from numba import *\n",
        "import numba.cuda\n",
        "from numba.cuda import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rzzwLbhEnO3"
      },
      "source": [
        "# LAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNAQIxTREkgD",
        "outputId": "3e934121-b87e-46ed-f6b2-be59201384e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0             b'Tesla T4'                              [SUPPORTED]\n",
            "                      Compute Capability: 7.5\n",
            "                           PCI Device ID: 4\n",
            "                              PCI Bus ID: 0\n",
            "                                    UUID: GPU-4aba1185-72b7-18b1-d983-abe1d7e1552f\n",
            "                                Watchdog: Disabled\n",
            "             FP32/FP64 Performance Ratio: 32\n",
            "Summary:\n",
            "\t1/1 devices are supported\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numba.cuda.detect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxtvSsI7FOsn"
      },
      "source": [
        "only 1 cuda device available at index 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UtJ0itj_FOM7"
      },
      "outputs": [],
      "source": [
        "gpu = numba.cuda.select_device(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhKEwPp3HWm7",
        "outputId": "df7b4a26-097e-4f15-f1f8-b6f072097e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name :  b'Tesla T4'\n",
            "compute capability :  (7, 5)\n",
            "multiprocessors :  40\n"
          ]
        }
      ],
      "source": [
        "print(\"name : \", gpu.name)\n",
        "print(\"compute capability : \",gpu.compute_capability)\n",
        "print(\"multiprocessors : \", gpu.MULTIPROCESSOR_COUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7QVgBa_QLGY"
      },
      "source": [
        "We know that a (7,5) compute capability means a 64 core count (we could use a lookup dictionary instead to make it work for any gpu but it's a pain to make one so I didn't)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6bhqIa1M31k",
        "outputId": "acb5b980-26d9-4e06-a358-ab4b1ae48fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total cores :  2560\n"
          ]
        }
      ],
      "source": [
        "cores_per_sm = 64\n",
        "total_cores = gpu.MULTIPROCESSOR_COUNT * cores_per_sm\n",
        "\n",
        "print(\"total cores : \", total_cores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNQR91jTM3sR",
        "outputId": "531bbe44-a2e7-4fb9-fa26-f92b189a26c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Free Memory (in bytes): 15720382464\n",
            "Memory size: 15828320256\n"
          ]
        }
      ],
      "source": [
        "current_context=numba.cuda.current_context(0)\n",
        "free, total = current_context.get_memory_info()\n",
        "\n",
        "print(\"Free Memory (in bytes):\", str(free))\n",
        "print(\"Memory size:\", str(total))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
